{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we want to see how much our dependent variables (answers to our survey questions) can be explained by our demographic information (ie race, sex, income, etc)\n",
    "- our dependent variables are *nominal*, meaning they are categorical (NOT continuous) -- this means we need to use a different kind of regression (we can't use simple linear regression)\n",
    "- because our *dependent variable is nominal* we want to use *logistic regression*, not linear regression\n",
    "- in addition, our nominal data is *ordinal*, meaning that it is a scale -- our survey answer choices all range from least amount of agreeance to the most\n",
    "- so, we must use *ordinal logistic regression* -- this is because, with regular logistic regression, we assume that for our nominal dependent variables, each is a double of the last. This would mean we're assuming that people who choose answer 2 are agreeing 2x as much with the statement. We can't safely make this assumption, and in addition, the way our survey choices were written does not imply to the respondent that is what is meant. So this is why we want to go with this method (\"We only know that a rating of 2 is better than a rating of 1, but we don’t know by how much. Such data is essentially a ranking, i.e. ordinal data. It’s better to think of ratings as categories which are ordered from very bad to excellent.\" [2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of multiple ordered response categories include bond ratings, opinion surveys with responses ranging from \"strongly agree\" to \"strongly disagree,\" [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] https://statisticsbyjim.com/regression/choosing-regression-analysis/\n",
    "\n",
    "[2] https://rikunert.com/ordinal_rating\n",
    "\n",
    "[3] https://en.wikipedia.org/wiki/Ordered_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mord\n",
    "from os.path import dirname, join\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets.base import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from mord.datasets.base import load_housing\n",
    "from sklearn import linear_model, metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error of LogisticRegression: 0.6805472932778108\n",
      "Mean Absolute Error of LogisticAT 0.6287923854848304\n",
      "Mean Absolute Error of LogisticIT 0.7441998810232004\n",
      "Mean Absolute Error of LogisticSE 0.6627007733491969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:43: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = load_housing()\n",
    "features = data.data\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data.target)\n",
    "data.target = le.transform(data.target)\n",
    "\n",
    "features.loc[features.Infl == 'Low', 'Infl'] = 1\n",
    "features.loc[features.Infl == 'Medium', 'Infl'] = 2\n",
    "features.loc[features.Infl == 'High', 'Infl'] = 3\n",
    "\n",
    "features.loc[features.Cont == 'Low', 'Cont'] = 1\n",
    "features.loc[features.Cont == 'Medium', 'Cont'] = 2\n",
    "features.loc[features.Cont == 'High', 'Cont'] = 3\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(features.loc[:,'Type'])\n",
    "features.loc[:,'type_encoded'] = le.transform(features.loc[:,'Type'])\n",
    "\n",
    "X, y = features.loc[:,('Infl', 'Cont', 'type_encoded')], data.target\n",
    "\n",
    "clf1 = linear_model.LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    multi_class='multinomial')\n",
    "clf1.fit(X, y)\n",
    "\n",
    "print('Mean Absolute Error of LogisticRegression: %s' %\n",
    "      metrics.mean_absolute_error(clf1.predict(X), y))\n",
    "\n",
    "clf2 = mord.LogisticAT(alpha=1.)\n",
    "clf2.fit(X, y)\n",
    "print('Mean Absolute Error of LogisticAT %s' %\n",
    "      metrics.mean_absolute_error(clf2.predict(X), y))\n",
    "\n",
    "clf3 = mord.LogisticIT(alpha=1.)\n",
    "clf3.fit(X, y)\n",
    "print('Mean Absolute Error of LogisticIT %s' %\n",
    "      metrics.mean_absolute_error(clf3.predict(X), y))\n",
    "\n",
    "clf4 = mord.LogisticSE(alpha=1.)\n",
    "clf4.fit(X, y)\n",
    "print('Mean Absolute Error of LogisticSE %s' %\n",
    "      metrics.mean_absolute_error(clf4.predict(X), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing():\n",
    "    from pandas import read_csv\n",
    "    \"\"\"Load and return the Copenhagen housing survey dataset\n",
    "       (ordinal classification).\n",
    "    ==============     ==============\n",
    "    Samples total                1681\n",
    "    Dimensionality                  3\n",
    "    Features              categorical\n",
    "    Targets       ordered categorical\n",
    "    ==============     ==============\n",
    "    Returns\n",
    "    -------\n",
    "    data : Bunch\n",
    "        Dictionary-like object, the interesting attributes are:\n",
    "        'data', the data to learn, 'target', the classification targets,\n",
    "        and 'DESCR', the full description of the dataset.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_housing\n",
    "    >>> housing = load_housing()\n",
    "    >>> print(housing.data.shape)\n",
    "    (506, 13)\n",
    "    \"\"\"\n",
    "    module_path = dirname('testdata.csv')\n",
    "    print(module_path)\n",
    "\n",
    "    #fdescr_name = join(module_path, 'descr', 'copenhagen_housing_survey.rst')\n",
    "    #with open(fdescr_name) as f:\n",
    "    #    descr_text = f.read()\n",
    "\n",
    "    #data_file_name = join(module_path, 'data', 'copenhagen_housing_survey.csv')\n",
    "    data = read_csv('../testdata.csv')\n",
    "\n",
    "    '''\n",
    "    Original data set is formatted as a frequency table,\n",
    "    but it's more convenient to work with the data\n",
    "    as having one row per observation, below duplicates\n",
    "    each obs by index based on the number the frequency ('Freq')\n",
    "    of appearance\n",
    "    '''\n",
    "    index = np.asarray(range(0, data.shape[0])).\\\n",
    "        repeat(data.ix[:,'Freq'].values)\n",
    "    data = data.ix[index,:]\n",
    "    features = ('Infl', 'Type', 'Cont')\n",
    "\n",
    "    return Bunch(data=data.loc[:,features],\n",
    "                 target=data.loc[:,'Sat'],\n",
    "                 feature_names=features,\n",
    "                 DESCR=\"descr_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
